{
  "name": "prompt-eng",
  "version": "1.0.31",
  "description": "Tool for prompt caching openai gpt responses. It will store your prompt template as well as parameters in local cache and use it next time you send the same request.",
  "main": "bin/prompt.js",
  "homepage": "https://github.com/blinq-io/prompts",
  "bugs": {
    "url": "https://github.com/blinq-io/prompts/issues"
  },
  "keywords": [
    "cache",
    "test",
    "prompt-engineering",
    "automation",
    "dev",
    "production",
    "openai"
  ],
  "scripts": {
    "pack": "npm version patch && mkdir build && mkdir build/bin && cp ./src/prompt.js ./build/bin/prompt.js && cp ./src/queue.js ./build/bin/queue.js && cp ./package.json ./build/package.json && cp ./README.md ./build/README.md",
    "clean": "rm -rf ./build",
    "build": "npm run clean && npm run pack",
    "test": "mocha --file './test/cacheTest.js' ",
    "test:dev": "cross-env NODE_ENV=dev mocha --file './test/cacheTest.js'"
  },
  "author": "blinq.io",
  "license": "ISC",
  "dependencies": {
    "axios": "^1.4.0",
    "cross-env": "^7.0.3",
    "dotenv": "^16.1.4",
    "md5": "^2.3.0",
    "openai": "^3.2.1"
  },
  "devDependencies": {
    "chai": "^4.3.7",
    "mocha": "^10.2.0"
  }
}
